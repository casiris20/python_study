{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  CIFAR 10 이미지 분류하기\n",
    "\n",
    "- 이미지 데이터를 읽고, 라벨을 직접 만들어서 딥러닝 CNN 모델로 인식하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://pjreddie.com/projects/cifar-10-dataset-mirror/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "작업 순서\n",
    "1. 데이터셋 획득 Download/ 압축 해제\n",
    "2. (X)이미지 > 수치 배열로 변환 , (Y)이미지의 클래스-라벨\n",
    "3. 정규화(0~1) Normalization - 모델안에서 구현\n",
    "4. CNN 모델을 구현\n",
    "5. trainset 으로 학습\n",
    "6. testset 성능을 평가(accuracy 정확도), confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 이미지 1장 읽기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDER_ROOT = './cifar/'\n",
    "sample = FOLDER_ROOT + 'train/0_frog.png'\n",
    "FOLDER_TRAIN  = FOLDER_ROOT + 'train/*.png'\n",
    "FOLDER_TEST   = FOLDER_ROOT + 'test/*.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=RGB size=32x32 at 0x1A186001780>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = Image.open(sample)\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 32, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = np.array(image)\n",
    "arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./cifar/train/0_frog.png'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = sample.index('_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "end = sample.index('.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'frog'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label = sample[start+1:end]\n",
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_str = ['airplane','automobile','bird','cat','deer','dog','frog','horse','ship','truck']\n",
    "len(class_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_str.index(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, ['./cifar/train\\\\0_frog.png', './cifar/train\\\\10000_automobile.png'])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_train = glob.glob(FOLDER_TRAIN)\n",
    "len(path_train), path_train[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_folder(folder, m_max):\n",
    "    path_train = glob.glob(folder)\n",
    "    m = np.minimum(m_max,len(path_train))\n",
    "    list_x = []\n",
    "    list_y = []\n",
    "    for i in range(m):\n",
    "        path_img = path_train[i]\n",
    "        image = Image.open(path_img)\n",
    "        arr = np.array(image)\n",
    "        list_x.append(arr)\n",
    "        \n",
    "        start = path_img.index('_')\n",
    "        end = path_img.index('.png')\n",
    "        label = path_img[start+1:end]\n",
    "        label_index = class_str.index(label)\n",
    "        list_y.append(label_index)\n",
    "    \n",
    "    return np.array(list_x), np.array(list_y)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000, 32, 32, 3), (1000,), (1000, 32, 32, 3), (1000,))"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_max = 1000\n",
    "train_x, train_y = parse_folder(FOLDER_TRAIN, m_max)\n",
    "test_x, test_y = parse_folder(FOLDER_TEST, m_max)\n",
    "train_x.shape, train_y.shape, test_x.shape, test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('uint8')"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN 모델 구현 : 네트워크를 어떻게 구성할것인가\n",
    "- 입력데이터 : (32, 32, 3) (높이, 너비, 채널) 개구리\n",
    "- 중간을 conv, pooling 으로 구성을 한다.\n",
    "- conv : kernel (3x3), output : 16, stride 1, paddig='SAME' > (32, 32, 16) \n",
    "- max pool : kernel (2x2), stride 2 > (16, 16, 16)\n",
    "- conv : kernel (3x3), output : 32, stride 1 > (16, 16, 32)\n",
    "- max pool : kernel (4x4), stride 4 > (4, 4, 16)\n",
    "- conv : kernel (4x4), output : 10, stride 1, padding='VALID' > (1, 1, 10)\n",
    "- (1,1,10) > [0,0] > (10), flatten(펼치다)\n",
    "- 출력 : (10) : 10개의 클래스 중 무엇이냐 score \n",
    "         'airplane','automobile','bird','cat','deer','dog','frog','horse','ship','truck'\n",
    "         (   5점,        3점,      7점,   8점...      9점,   30점,   12점,  3점,   4점   )\n",
    "          \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.contrib.slim as slim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feed(X):\n",
    "    #X : (m:1000, 32, 32, 3) X 값 [0~255] uint8\n",
    "    x_norm = tf.cast(X, tf.float32) / 255.0 # [0.0 ~ 1.0]  실수\n",
    "    net = slim.conv2d(x_norm, 16, (3,3))\n",
    "    print('net', net)\n",
    "    net = slim.max_pool2d(net, (2,2), 2)\n",
    "    print('net', net)\n",
    "    net = slim.conv2d(net, 32, (3,3))\n",
    "    print('net', net)\n",
    "    net = slim.max_pool2d(net, (4,4), 4)\n",
    "    print('net', net)\n",
    "    net = slim.conv2d(net, 10, (4,4), 4, padding='VALID')\n",
    "    print('net', net)# (m, 1, 1, 10)\n",
    "    score = net[:,0,0] # (m:1000, 10)\n",
    "    score = slim.flatten(net)\n",
    "    print('score', score)\n",
    "    return score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "net Tensor(\"Conv_12/Relu:0\", shape=(?, 32, 32, 16), dtype=float32)\n",
      "net Tensor(\"MaxPool2D_8/MaxPool:0\", shape=(?, 16, 16, 16), dtype=float32)\n",
      "net Tensor(\"Conv_13/Relu:0\", shape=(?, 16, 16, 32), dtype=float32)\n",
      "net Tensor(\"MaxPool2D_9/MaxPool:0\", shape=(?, 4, 4, 32), dtype=float32)\n",
      "net Tensor(\"Conv_14/Relu:0\", shape=(?, 1, 1, 10), dtype=float32)\n",
      "score Tensor(\"Flatten_1/flatten/Reshape:0\", shape=(?, 10), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "m, h, w, c = tain_x.shape\n",
    "PX = tf.placeholder(tf.uint8, [None, h, w, c])\n",
    "PY = tf.placeholder(tf.int64, [None])\n",
    "score = feed(PX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = tf.argmax(score, axis=1)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predict, PY),tf.float32)) # True > 1.0, False > 0.0\n",
    "cost = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(labels=PY, logits=score))\n",
    "opt = tf.train.GradientDescentOptimizer(0.01)\n",
    "train_op = opt.minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0, cost:0.87770, acc:(0.68, 0.35)\n",
      "100, cost:0.79964, acc:(0.68, 0.35)\n",
      "200, cost:0.79580, acc:(0.68, 0.35)\n",
      "300, cost:0.79781, acc:(0.68, 0.35)\n",
      "400, cost:0.79593, acc:(0.68, 0.35)\n",
      "500, cost:0.79264, acc:(0.68, 0.36)\n",
      "600, cost:0.79015, acc:(0.68, 0.35)\n",
      "700, cost:0.78965, acc:(0.68, 0.35)\n",
      "800, cost:0.78694, acc:(0.68, 0.35)\n",
      "900, cost:0.78583, acc:(0.68, 0.35)\n",
      "1000, cost:0.78463, acc:(0.68, 0.35)\n",
      "1100, cost:0.78643, acc:(0.68, 0.36)\n",
      "1200, cost:0.78286, acc:(0.68, 0.35)\n",
      "1300, cost:0.78995, acc:(0.68, 0.36)\n",
      "1400, cost:0.78787, acc:(0.68, 0.36)\n",
      "1500, cost:0.78060, acc:(0.68, 0.36)\n",
      "1600, cost:0.77932, acc:(0.68, 0.35)\n",
      "1700, cost:0.77875, acc:(0.68, 0.35)\n",
      "1800, cost:0.77708, acc:(0.68, 0.35)\n",
      "1900, cost:0.77646, acc:(0.68, 0.35)\n",
      "2000, cost:0.77604, acc:(0.68, 0.35)\n",
      "2100, cost:0.77403, acc:(0.68, 0.35)\n",
      "2200, cost:0.77348, acc:(0.68, 0.35)\n",
      "2300, cost:0.77309, acc:(0.68, 0.35)\n",
      "2400, cost:0.77188, acc:(0.68, 0.36)\n",
      "2500, cost:0.77215, acc:(0.68, 0.36)\n",
      "2600, cost:0.77083, acc:(0.68, 0.36)\n",
      "2700, cost:0.77069, acc:(0.68, 0.35)\n",
      "2800, cost:0.77055, acc:(0.68, 0.36)\n",
      "2900, cost:0.77054, acc:(0.68, 0.36)\n",
      "3000, cost:0.76878, acc:(0.68, 0.36)\n",
      "3100, cost:0.76844, acc:(0.68, 0.35)\n",
      "3200, cost:0.76794, acc:(0.68, 0.35)\n",
      "3300, cost:0.76852, acc:(0.68, 0.36)\n",
      "3400, cost:0.76722, acc:(0.68, 0.35)\n",
      "3500, cost:0.76690, acc:(0.68, 0.36)\n",
      "3600, cost:0.76624, acc:(0.68, 0.36)\n",
      "3700, cost:0.76713, acc:(0.68, 0.36)\n",
      "3800, cost:0.76677, acc:(0.68, 0.36)\n",
      "3900, cost:0.76593, acc:(0.68, 0.36)\n",
      "4000, cost:0.76412, acc:(0.68, 0.36)\n",
      "4100, cost:0.76542, acc:(0.68, 0.36)\n",
      "4200, cost:0.76542, acc:(0.68, 0.36)\n",
      "4300, cost:0.76414, acc:(0.68, 0.36)\n",
      "4400, cost:0.76296, acc:(0.68, 0.36)\n",
      "4500, cost:0.76274, acc:(0.68, 0.36)\n",
      "4600, cost:0.76284, acc:(0.68, 0.36)\n",
      "4700, cost:0.76204, acc:(0.68, 0.36)\n",
      "4800, cost:0.76204, acc:(0.68, 0.35)\n",
      "4900, cost:0.76355, acc:(0.68, 0.35)\n"
     ]
    }
   ],
   "source": [
    "EPOCH = 5000\n",
    "for iter in range(EPOCH):\n",
    "    _, cost_train, acc_train = sess.run([train_op, cost, accuracy], feed_dict={PX:tain_x, PY:train_y})\n",
    "    if iter%100==0:\n",
    "        acc_test = sess.run(accuracy, feed_dict={PX:test_x, PY:test_y})\n",
    "        print(\"%d, cost:%.5f, acc:(%.2f, %.2f)\" %(iter, cost_train, acc_train, acc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['airplane',\n",
       " 'automobile',\n",
       " 'bird',\n",
       " 'cat',\n",
       " 'deer',\n",
       " 'dog',\n",
       " 'frog',\n",
       " 'horse',\n",
       " 'ship',\n",
       " 'truck']"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 99,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  4,  96,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [ 52,   2,  15,   0,   8,   0,   2,   1,   0,   0],\n",
       "       [ 15,   0,   0,  82,   0,   0,   0,   0,   1,   0],\n",
       "       [ 16,   1,   0,   0,  88,   0,   0,   0,   0,   0],\n",
       "       [ 89,   1,   0,   0,   2,   0,   1,   1,   0,   0],\n",
       "       [  8,   1,   0,   0,   0,   0,  93,   0,   0,   0],\n",
       "       [  7,   1,   0,   0,   0,   0,   0, 109,   0,   0],\n",
       "       [  9,   1,   0,   0,   1,   0,   0,   0, 100,   0],\n",
       "       [ 76,  16,   0,   0,   0,   0,   0,   0,   2,   0]], dtype=int64)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_y = sess.run(predict, feed_dict={PX:tain_x})\n",
    "confusion_matrix(train_y, pred_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[58, 10,  1,  3,  5,  0,  2,  1, 14,  0],\n",
       "       [18, 60,  2,  5,  1,  0,  5,  4, 12,  0],\n",
       "       [34,  4,  4, 15, 21,  0,  8,  9,  2,  0],\n",
       "       [17,  9,  4, 31,  8,  0, 14,  9,  3,  0],\n",
       "       [12,  6,  0, 14, 46,  0, 12, 13,  2,  0],\n",
       "       [26,  4,  7, 21, 11,  0, 11, 17,  3,  0],\n",
       "       [ 8,  6,  1, 13, 13,  0, 51,  9,  0,  0],\n",
       "       [20,  4,  2, 10, 10,  0,  1, 42,  1,  0],\n",
       "       [29, 15,  1,  0,  3,  0,  2,  2, 63,  0],\n",
       "       [31, 26,  0,  6,  4,  0,  8,  9, 12,  0]], dtype=int64)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_y = sess.run(predict, feed_dict={PX:test_x})\n",
    "confusion_matrix(test_y, pred_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
